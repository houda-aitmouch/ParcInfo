#!/usr/bin/env python3
"""
Script d'analyse des performances du chatbot ParcInfo
Analyse les r√©sultats des tests progressifs et g√©n√®re un rapport d√©taill√©
"""

import json
import os
from datetime import datetime

def analyze_chatbot_performance(test_file):
    """Analyse les performances du chatbot √† partir du fichier de test"""
    
    print("üîç ANALYSE DES PERFORMANCES DU CHATBOT PARCINFO")
    print("=" * 80)
    
    # Charger les r√©sultats
    with open(test_file, 'r', encoding='utf-8') as f:
        results = json.load(f)
    
    # Statistiques globales
    total_questions = 0
    total_successful = 0
    total_processing_time = 0
    confidence_scores = []
    
    # Analyse par cat√©gorie
    category_analysis = {}
    
    for category, questions in results["categories"].items():
        category_total = len(questions)
        category_success = sum(1 for q in questions if q["status"] == "success")
        category_processing_time = sum(q["processing_time"] for q in questions if q["status"] == "success")
        category_confidence = [q["confidence"] for q in questions if q["status"] == "success"]
        
        # M√©thodes utilis√©es
        methods = {}
        sources = {}
        intents = {}
        
        for q in questions:
            if q["status"] == "success":
                method = q["method"]
                source = q["source"]
                intent = q["intent"]
                
                methods[method] = methods.get(method, 0) + 1
                sources[source] = sources.get(source, 0) + 1
                intents[intent] = intents.get(intent, 0) + 1
        
        category_analysis[category] = {
            "total": category_total,
            "success": category_success,
            "success_rate": (category_success / category_total) * 100,
            "avg_processing_time": category_processing_time / category_success if category_success > 0 else 0,
            "avg_confidence": sum(category_confidence) / len(category_confidence) if category_confidence else 0,
            "methods": methods,
            "sources": sources,
            "intents": intents
        }
        
        total_questions += category_total
        total_successful += category_success
        total_processing_time += category_processing_time
        confidence_scores.extend(category_confidence)
    
    # Affichage des r√©sultats
    print(f"\nüìä R√âSULTATS GLOBAUX")
    print(f"   Total des questions : {total_questions}")
    print(f"   Questions r√©ussies : {total_successful}")
    print(f"   Taux de r√©ussite global : {(total_successful/total_questions)*100:.1f}%")
    print(f"   Temps de traitement moyen : {total_processing_time/total_successful:.3f}s")
    print(f"   Confiance moyenne : {sum(confidence_scores)/len(confidence_scores):.1f}")
    
    # Analyse par cat√©gorie
    print(f"\nüìã ANALYSE PAR CAT√âGORIE")
    print("=" * 80)
    
    for category, analysis in category_analysis.items():
        print(f"\n{category}")
        print(f"   Questions : {analysis['total']}")
        print(f"   Taux de r√©ussite : {analysis['success_rate']:.1f}%")
        print(f"   Temps moyen : {analysis['avg_processing_time']:.3f}s")
        print(f"   Confiance moyenne : {analysis['avg_confidence']:.1f}")
        
        print(f"   M√©thodes utilis√©es :")
        for method, count in analysis['methods'].items():
            percentage = (count / analysis['success']) * 100
            print(f"     ‚Ä¢ {method}: {count} ({percentage:.1f}%)")
        
        print(f"   Sources de donn√©es :")
        for source, count in analysis['sources'].items():
            percentage = (count / analysis['success']) * 100
            print(f"     ‚Ä¢ {source}: {count} ({percentage:.1f}%)")
    
    # Analyse des performances
    print(f"\nüöÄ ANALYSE DES PERFORMANCES")
    print("=" * 80)
    
    # Questions les plus rapides
    all_questions = []
    for category, questions in results["categories"].items():
        for q in questions:
            if q["status"] == "success":
                all_questions.append({
                    "question": q["question"],
                    "processing_time": q["processing_time"],
                    "confidence": q["confidence"],
                    "method": q["method"],
                    "category": category
                })
    
    # Top 5 des questions les plus rapides
    fastest_questions = sorted(all_questions, key=lambda x: x["processing_time"])[:5]
    print(f"\n‚ö° TOP 5 - Questions les plus rapides :")
    for i, q in enumerate(fastest_questions, 1):
        print(f"   {i}. {q['question'][:60]}... ({q['processing_time']:.3f}s, conf: {q['confidence']})")
    
    # Top 5 des questions les plus lentes
    slowest_questions = sorted(all_questions, key=lambda x: x["processing_time"], reverse=True)[:5]
    print(f"\nüêå TOP 5 - Questions les plus lentes :")
    for i, q in enumerate(slowest_questions, 1):
        print(f"   {i}. {q['question'][:60]}... ({q['processing_time']:.3f}s, conf: {q['confidence']})")
    
    # Questions avec la plus haute confiance
    highest_confidence = sorted(all_questions, key=lambda x: x["confidence"], reverse=True)[:5]
    print(f"\nüéØ TOP 5 - Questions avec la plus haute confiance :")
    for i, q in enumerate(highest_confidence, 1):
        print(f"   {i}. {q['question'][:60]}... (conf: {q['confidence']}, {q['processing_time']:.3f}s)")
    
    # Questions avec la plus basse confiance
    lowest_confidence = sorted(all_questions, key=lambda x: x["confidence"])[:5]
    print(f"\n‚ùì TOP 5 - Questions avec la plus basse confiance :")
    for i, q in enumerate(lowest_confidence, 1):
        print(f"   {i}. {q['question'][:60]}... (conf: {q['confidence']}, {q['processing_time']:.3f}s)")
    
    # Analyse des m√©thodes
    print(f"\nüîß ANALYSE DES M√âTHODES")
    print("=" * 80)
    
    method_stats = {}
    for q in all_questions:
        method = q["method"]
        if method not in method_stats:
            method_stats[method] = {"count": 0, "total_time": 0, "confidences": []}
        
        method_stats[method]["count"] += 1
        method_stats[method]["total_time"] += q["processing_time"]
        method_stats[method]["confidences"].append(q["confidence"])
    
    for method, stats in method_stats.items():
        avg_time = stats["total_time"] / stats["count"]
        avg_confidence = sum(stats["confidences"]) / len(stats["confidences"])
        print(f"\n   {method}:")
        print(f"     ‚Ä¢ Utilis√©e : {stats['count']} fois")
        print(f"     ‚Ä¢ Temps moyen : {avg_time:.3f}s")
        print(f"     ‚Ä¢ Confiance moyenne : {avg_confidence:.1f}")
    
    # Recommandations
    print(f"\nüí° RECOMMANDATIONS")
    print("=" * 80)
    
    if category_analysis["üü¢ Facile ‚Äî Questions directes (donn√©es brutes)"]["success_rate"] < 95:
        print("   ‚Ä¢ Am√©liorer la reconnaissance des questions simples")
    
    if category_analysis["üü° Interm√©diaire ‚Äî Filtres simples & conditions"]["success_rate"] < 90:
        print("   ‚Ä¢ Optimiser la gestion des filtres et conditions")
    
    if category_analysis["üî¥ Difficile ‚Äî Analyse crois√©e & statistiques"]["success_rate"] < 85:
        print("   ‚Ä¢ Renforcer les capacit√©s d'analyse crois√©e")
    
    # Identifier les m√©thodes lentes
    slow_methods = [method for method, stats in method_stats.items() 
                    if stats["total_time"] / stats["count"] > 1.0]
    if slow_methods:
        print(f"   ‚Ä¢ Optimiser les m√©thodes lentes : {', '.join(slow_methods)}")
    
    # Identifier les m√©thodes avec faible confiance
    low_confidence_methods = [method for method, stats in method_stats.items() 
                             if sum(stats["confidences"]) / len(stats["confidences"]) < 50]
    if low_confidence_methods:
        print(f"   ‚Ä¢ Am√©liorer la confiance des m√©thodes : {', '.join(low_confidence_methods)}")
    
    print(f"\n‚úÖ Analyse termin√©e !")
    return category_analysis

if __name__ == "__main__":
    # Chercher le fichier de test le plus r√©cent
    test_files = [f for f in os.listdir('.') if f.startswith('progressive_questions_test_') and f.endswith('.json')]
    
    if not test_files:
        print("‚ùå Aucun fichier de test trouv√©")
        exit(1)
    
    # Prendre le plus r√©cent
    latest_test = max(test_files)
    print(f"üìÅ Fichier de test utilis√© : {latest_test}")
    
    # Analyser les performances
    analysis = analyze_chatbot_performance(latest_test)
