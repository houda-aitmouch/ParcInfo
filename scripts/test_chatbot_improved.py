#!/usr/bin/env python3
"""
Test script for the improved ParcInfo Chatbot
Tests the corrected functionality and improved precision
"""

import os
import sys
import django
import json
from datetime import datetime

# Add the project root to the Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Setup Django environment
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ParcInfo.settings')
django.setup()

from apps.chatbot.core_chatbot_improved import ParcInfoChatbotImproved

def test_improved_chatbot():
    """Test the improved chatbot with specific problematic queries"""
    
    print("üöÄ Testing Improved ParcInfo Chatbot...")
    print("=" * 60)
    
    # Initialize the improved chatbot
    try:
        chatbot = ParcInfoChatbotImproved()
        print("‚úÖ Chatbot initialized successfully")
    except Exception as e:
        print(f"‚ùå Failed to initialize chatbot: {e}")
        return
    
    # Test cases that were problematic in the original version
    test_cases = [
        {
            "category": "üü¢ Questions Faciles (Corrig√©es)",
            "questions": [
                "Qui est le super admin ?",
                "Liste des fournisseurs",
                "Donne-moi les commandes r√©centes",
                "Montre-moi la liste du mat√©riel en service",
                "Quels sont les utilisateurs du syst√®me ?",
                "Livraisons √† venir",
                "Code inventaire de la baie"
            ]
        },
        {
            "category": "üü° Questions Interm√©diaires (Corrig√©es)",
            "questions": [
                "Quels sont les √©quipements non affect√©s ?",
                "Quels utilisateurs n'ont encore rien re√ßu comme mat√©riel ?",
                "Qui utilise le mat√©riel avec le code inventaire cd12 ?",
                "Donne-moi les √©quipements du type 'PC' stock√©s √† l'√©tage 1",
                "Quels fournisseurs ont livr√© plus de 3 √©quipements ?",
                "Quel est le nom du fournisseur qui a livr√© l'√©quipement eq18 ?",
                "Commandes livr√©es mais avec un √©quipement non encore affect√©"
            ]
        },
        {
            "category": "üî¥ Questions Complexes (Corrig√©es)",
            "questions": [
                "Quel est le fournisseur ayant livr√© le plus de mat√©riel au total ?",
                "Taux de livraison des commandes contenant du mat√©riel informatique",
                "Combien d'√©quipements en bon √©tat, non affect√©s, sont actuellement en stock ?",
                "Pourcentage des √©quipements affect√©s qui ont √©t√© command√©s en 2023",
                "Historique complet de l'√©quipement EQ18 : commande, livraison, affectation",
                "Fournisseurs ayant livr√© √† la fois du mat√©riel informatique et bureautique",
                "R√©sum√© par type (PC, serveur, imprimante) avec nombre total, livr√©s et affect√©s"
            ]
        }
    ]
    
    results = {}
    
    for test_category in test_cases:
        category = test_category["category"]
        questions = test_category["questions"]
        
        print(f"\n{category}")
        print("-" * 50)
        
        results[category] = []
        
        for i, question in enumerate(questions, 1):
            print(f"\n{i}. Question: {question}")
            
            try:
                start_time = datetime.now()
                
                # Process the query
                response = chatbot.process_query(question)
                
                end_time = datetime.now()
                processing_time = (end_time - start_time).total_seconds()
                
                # Extract response text
                if isinstance(response, dict):
                    response_text = response.get('response', str(response))
                    confidence = response.get('confidence', 0)
                    method = response.get('method', 'unknown')
                else:
                    response_text = str(response)
                    confidence = 0
                    method = 'unknown'
                
                # Analyze response quality
                quality_score = analyze_response_quality(question, response_text)
                
                print(f"   ‚è±Ô∏è  Temps: {processing_time:.3f}s")
                print(f"   üéØ Confiance: {confidence}")
                print(f"   üîß M√©thode: {method}")
                print(f"   üìä Qualit√©: {quality_score}/100")
                print(f"   üí¨ R√©ponse: {response_text[:200]}{'...' if len(response_text) > 200 else ''}")
                
                # Store results
                results[category].append({
                    "question": question,
                    "response": response_text,
                    "processing_time": processing_time,
                    "confidence": confidence,
                    "method": method,
                    "quality_score": quality_score,
                    "success": quality_score >= 70
                })
                
            except Exception as e:
                print(f"   ‚ùå Erreur: {e}")
                results[category].append({
                    "question": question,
                    "error": str(e),
                    "success": False
                })
    
    # Generate summary report
    generate_summary_report(results)
    
    # Save detailed results
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"improved_chatbot_test_{timestamp}.json"
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nüìÅ R√©sultats d√©taill√©s sauvegard√©s dans: {results_file}")

def analyze_response_quality(question: str, response: str) -> int:
    """Analyze the quality of a chatbot response"""
    if not response or len(response.strip()) < 10:
        return 0
    
    score = 0
    
    # Length score (0-20 points)
    if len(response) > 100:
        score += 20
    elif len(response) > 50:
        score += 15
    elif len(response) > 20:
        score += 10
    else:
        score += 5
    
    # Relevance score (0-30 points)
    question_lower = question.lower()
    response_lower = response.lower()
    
    # Check if response contains relevant keywords
    relevant_words = extract_relevant_words(question_lower)
    found_words = sum(1 for word in relevant_words if word in response_lower)
    
    if found_words > 0:
        score += min(30, (found_words / len(relevant_words)) * 30)
    
    # Structure score (0-25 points)
    if any(marker in response for marker in ['‚Ä¢', '-', '*', '1.', '2.']):
        score += 15  # Has bullet points
    if any(marker in response for marker in ['**', '__', '==']):
        score += 10  # Has formatting
    
    # Completeness score (0-25 points)
    if 'aucun' not in response_lower or 'trouv√©' not in response_lower:
        score += 15  # Not a "no results" response
    if len(response.split('\n')) > 3:
        score += 10  # Multiple lines of content
    
    return min(100, int(score))

def extract_relevant_words(question: str) -> list:
    """Extract relevant words from a question for relevance checking"""
    # Remove common words
    stop_words = {
        'qui', 'est', 'les', 'des', 'du', 'de', 'la', 'le', 'et', 'ou', 'avec',
        'pour', 'dans', 'sur', 'par', 'vers', 'chez', 'que', 'quel', 'quelle',
        'quels', 'quelles', 'sont', 'ont', 'a', '√†', 'un', 'une', 'au', 'aux'
    }
    
    words = question.split()
    relevant = [word for word in words if len(word) > 2 and word not in stop_words]
    
    return relevant

def generate_summary_report(results: dict):
    """Generate a summary report of the test results"""
    print("\n" + "=" * 60)
    print("üìä RAPPORT DE TEST - CHATBOT AM√âLIOR√â")
    print("=" * 60)
    
    total_questions = 0
    total_successful = 0
    total_processing_time = 0
    total_quality_score = 0
    
    for category, questions in results.items():
        print(f"\n{category}")
        print("-" * 40)
        
        category_questions = len(questions)
        category_successful = sum(1 for q in questions if q.get('success', False))
        category_avg_time = sum(q.get('processing_time', 0) for q in questions) / category_questions if category_questions > 0 else 0
        category_avg_quality = sum(q.get('quality_score', 0) for q in questions) / category_questions if category_questions > 0 else 0
        
        print(f"Questions: {category_questions}")
        print(f"R√©ussites: {category_successful}/{category_questions} ({category_successful/category_questions*100:.1f}%)")
        print(f"Temps moyen: {category_avg_time:.3f}s")
        print(f"Qualit√© moyenne: {category_avg_quality:.1f}/100")
        
        total_questions += category_questions
        total_successful += category_successful
        total_processing_time += sum(q.get('processing_time', 0) for q in questions)
        total_quality_score += sum(q.get('quality_score', 0) for q in questions)
    
    print("\n" + "=" * 60)
    print("üìà R√âSULTATS GLOBAUX")
    print("=" * 60)
    print(f"Total des questions: {total_questions}")
    print(f"Total des r√©ussites: {total_successful}/{total_questions} ({total_successful/total_questions*100:.1f}%)")
    print(f"Temps de traitement moyen: {total_processing_time/total_questions:.3f}s")
    print(f"Qualit√© moyenne globale: {total_quality_score/total_questions:.1f}/100")
    
    # Improvement assessment
    if total_successful/total_questions >= 0.8:
        print("\nüéâ EXCELLENT! Le chatbot am√©lior√© fonctionne tr√®s bien!")
    elif total_successful/total_questions >= 0.6:
        print("\n‚úÖ BON! Le chatbot am√©lior√© montre une am√©lioration significative!")
    elif total_successful/total_questions >= 0.4:
        print("\n‚ö†Ô∏è MOYEN! Le chatbot am√©lior√© montre quelques am√©liorations.")
    else:
        print("\n‚ùå INSUFFISANT! Le chatbot am√©lior√© n√©cessite plus de corrections.")

if __name__ == "__main__":
    test_improved_chatbot()
